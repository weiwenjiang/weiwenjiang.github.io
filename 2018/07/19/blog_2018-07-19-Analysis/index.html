<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="google-site-verification" content="x769ihcPpzMLLAP03TIykIjylrYsAghgJfwpvP8LZ14" />
  <meta name="msvalidate.01" content="ECCB0341CC24C59E0D3F85526AB31105" />
  <meta name="viewport" content="target-densitydpi=device-dpi, width=device-width, initial-scale=1.0, minimum-scale=1.0, maximum-scale=1.5, user-scalable=yes">
  <!-- 
  <title>Usage Analysis NN on ZCU102 (1) --- Memory Usage | Weiwen Jiang | Home Page</title>
 -->
  <title>Weiwen Jiang | Home Page</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <!--<link rel="stylesheet" href="./css/application.css">-->
  <link rel="stylesheet" href="/css/style.css">
  <link rel="stylesheet" href="/css/application.css">
  

  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">

  <script type="text/x-mathjax-config">
	  MathJax.Hub.Config({
		tex2jax: {
		  inlineMath: [ ['$','$'], ["\\(","\\)"] ],
		  processEscapes: true
		}
	  });
  </script>  
  <script type="text/javascript" async
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML"></script>
  
  <!--<script src="./js/application.js"></script>-->
</head>

<body style="background: url(/css/images/bg.png) 0 0 repeat; ">
  <header id="header" role="banner" class="site-header" style="height:138px;  min-width:1200px;">
      <nav class="brandbar theme-bb-blue container-fluid">
        <ul class="row">
          <li class="dept-nd col-lg-6"><a href="https://www.nd.edu/">University of Notre Dame</a></li>
          <li class="dept dept-current col-lg-5">
          <a href="http://engineering.nd.edu/" title="College of Engineering" target="_blank">COLLEGE of ENGINEERING</a>
          </li>
        </ul>
      </nav>
      <div class="titlebar theme-tb-gold container-fluid">
        <div class="row">
          <div class="col">
            <h1 class="site-title"><a href="/" accesskey="H">Weiwen Jiang's Personal Website</a></h1>
          </div>
          <div style="float:right; margin-top:30px; margin-right:120px;">
            <form method="get" action="https://google.com/search" role="search">
              <input type="search" name="q" placeholder="Search">
              <button type="submit" style="float:right;"><i class="fa fa-search"></i></button>
            </form>
          </div>
        </div>
      </div>
  </header>
    
  <div id="container" style="background: url(/css/images/bg.png) 0 0 repeat; ">
    <div id="wrap" style="background: url(/css/images/bg.png) 0 0 repeat; ">
      <div style="height: 60px; min-width: 1200px;" >
<div  id="hearder" style=" border-bottom: 2px solid #dcb439;  ">
  


  <div id="header-outer" class="outer" style=" width:1000px; ">
    <div id="header-inner" class="inner" style="margin-top: 0px;">
      <nav id="main-nav" style="margin-left: 0;">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
            
              <a class="main-nav-link" href="/" style="color: #000; font-weight: bold; background-color: #EFDB92;">Home</a>
            
        
            
              <a class="main-nav-link" href="/categories/paper" style="color: #000; ">Publication</a>
            
        
            
              <a class="main-nav-link" href="/categories/research" style="color: #000; ">Research</a>
            
        
            
              <a class="main-nav-link" href="/categories/teaching" style="color: #000; ">Teaching</a>
            
        
            
              <a class="main-nav-link" href="/categories/service" style="color: #000; ">Service</a>
            
        
            
              <a class="main-nav-link" href="/categories/awards" style="color: #000; ">Awards</a>
            
        
            
              <a class="main-nav-link" href="/categories/bio" style="color: #000; ">Bio</a>
            
        
            
              <a class="main-nav-link" href="/categories/QF" style="color: #000; ">QuantumFlow</a>
            
        
      </nav>                  
	  <!--<div style="float:right">
        <img src="/css/images/pitt_logo2.png" alt="pitt_log" height="48px" style="margin-top: 5px;">
	  </div>-->
    </div>
  </div>     
</div>
</div>









      <div class="outer" style="clear:both; width:1000px; min-height: 500px; margin-top:10px; padding-top:20px; padding-left:0px; padding-right:0px; padding-bottom: 30px; background: url(/css/images/bg.png) 0 0 repeat; ">
        <div>
    <article id="post-blog_2018-07-19-Analysis" class="article article-type-post" itemscope itemprop="blogPost">      
      <div class="article-inner" style="margin-top: -10px">
        
        
          <b><header class="article-header" style="font-size:24pt;">
            
      
      Usage Analysis NN on ZCU102 (1) --- Memory Usage    
  

          </header></b>
        
        <div class="article-entry" itemprop="articleBody">
          
            <p>In <a href="http://pitt.edu/~wej23/2018/07/13/blog_18-07-13/" target="_blank" rel="external">Design NN on ZCU102 (3)</a>, we have introduced the variables used in the design of NNs. In this blog, we are going to analyze the usage of hardware based on these variables.<br>There are two kinds of hardware usages we are targeting: (1) the memory usage, (2) DSP usage.<br>About the DSP usage, we consider the 16 bit fix-point for data related to ifm or intermidate data, which indicates the number of DSP used for one multiplication is 1.<br>Before going deeper, we first review the related variables. The last column “value” is the corresponding value of layer CONV3 in AlexNet.</p>
<table>
<thead>
<tr>
<th>Notations</th>
<th>Definition</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>ifm_ch_mem</td>
<td>The number of channels that the on-chip buffers can stored</td>
<td>8</td>
</tr>
<tr>
<td>ifm_ch_proc</td>
<td>The number of channels that will be processed in each iteration</td>
<td>4</td>
</tr>
<tr>
<td>ifm_len</td>
<td>The number of pixels in each channel of IFM</td>
<td>13*13</td>
</tr>
<tr>
<td>ifm_row,ifm_col</td>
<td>$I_{len}=ifm\_row\times ifm\_col$</td>
<td>13</td>
</tr>
<tr>
<td>ofm_ch_mem</td>
<td>The number of channels that the on-chip buffers can stored</td>
<td>4</td>
</tr>
<tr>
<td>ofm_ch_proc</td>
<td>The number of channels that will be processed in each iteration</td>
<td>4</td>
</tr>
<tr>
<td>ofm_len</td>
<td>The number of pixels in each channel of IFM</td>
<td>13*13</td>
</tr>
<tr>
<td>ofm_row,ifm_col</td>
<td>ofm_len=ofm_row*ofm_col</td>
<td>13</td>
</tr>
<tr>
<td>kernel_size</td>
<td>The size of a kernel</td>
<td>9</td>
</tr>
<tr>
<td>kernel_row</td>
<td>The number of rows in one kernel</td>
<td>3</td>
</tr>
<tr>
<td>win_pad_size</td>
<td>the padding for convolution</td>
<td>1</td>
</tr>
<tr>
<td>win_stride</td>
<td>the stride in performing convolution</td>
<td>1</td>
</tr>
</tbody>
</table>
<p>###Memory Usage in One Convolutional Layer</p>
<p>First, let’s see the memory usage of a convolutional layer.<br>It composed of several parts, including buffers for (1) input feature maps, denoted as “<strong>IFM_BUF</strong>“, (2) output feature maps, denoted as “<strong>OFM_BUF</strong>“, (3) kernels, denoted as “<strong>weight_BUF</strong>“, (4) bias, denoted as “<strong>BIAS_BUF</strong>“, (5) slide windows, denoted as “<strong>window_BUF</strong>“, (6) line buffers, denoted as “<strong>Line_BUF</strong>“, and (7) last line buffer “<strong>temp_BUF</strong>“. For the buffer types (5)-(7), please refer to <a href="http://pitt.edu/~wej23/2018/07/14/blog_18-07-14-Window/" target="_blank" rel="external">Design NN on ZCU102 (2)</a>.</p>
<p>#####IFM_BUF<br>$IFM\_BUF=ifm\_ch\_mem\times ifm\_len$</p>
<p>#####OFM_BUF<br>$OFM\_BUF=ofm\_ch\_mem\times ofm\_len$</p>
<p>#####weight_BUF<br>$weight\_BUF=ofm\_ch\_mem\times ifm\_ch\_mem\times kernel\_size$</p>
<p>#####BIAS_BUF<br>$BIAS\_BUF=ofm\_ch\_mem$</p>
<p>#####window_BUF<br>$window\_BUF=ifm\_ch\_proc*kernel\_size$</p>
<p>####Line_BUF<br>Note that, since some layer requires padding in convolution, we need to consider the padding in line buffer. For $3\times 3$ kernel, there are 2 line buffers. The size of each buffer is:<br>$Line\_BUF=ifm\_ch\_proc*(ifm\_col+win\_pad\_size+win\_pad\_size)$</p>
<p>####temp_BUF<br>For each channel, there is a temp buffer, which stores the last element for each row. Hence, its size is:<br>$temp\_BUF=ifm\_ch\_proc\times kernel\_row$</p>
<p>####Summary<br>We need to consider the bitwidth for each kind of buffer. For example, in the implementation, we can use 16-bit fix-point for IFM, OFM, window, Line buffer, temp buffer, while the weight and bias can be 8-bit fix-point to reduce the space of buffers. Here, we consider all data types are 16-bit fix-point for the ease of analysis.</p>
<p>In terms of the numbers in the above table, we can obtain the total memory usage of the IP core is: 3164, which equals 6328 Bytes.</p>
<p>###BRAM Usage in One Convolutional Layer<br>The above section analyzes the memory usage of one layer. However, these results cannot be directly applied to calculate the usage of on-chip memory (i.e., BRAM or LUTRAM on FPGA).<br>Before introducing the root cause of the above statement, we first present the property of BRAM in FPGA.<br>“<em>Unlike in DDR based main memory, BRAMs are distributed in one FPGA. The size of one BRAM is fixed, e.g., 16Kbit.</em>“</p>
<p>Now, let’s see the main reason that we cannot directly use the above calculations to obtain the usage of BRAM on an FPGA. The reason is:</p>
<ul>
<li><strong>We need high parallelism to accelerate the application, which requires us to retrieve/store data in parallel. In consequence, it is hard to fully occupy each BRAM.</strong></li>
</ul>
<p>In order to calculate the BRAM usage, we need understand how to allocate BRAM in FPGA. It involves the “<em>array partition</em>“. Let’s see an example of array partition as follows.</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">static FPGA_DATA IFM[ifm_ch_mem][ifm_len];</div><div class="line">#pragma HLS RESOURCE variable=IFM core=RAM_1P_BRAM</div><div class="line">#pragma HLS ARRAY_PARTITION variable=IFM cyclic factor=ifm_ch_proc dim=1</div></pre></td></tr></table></figure>
<p>In the above codes, we use single port BRAM to implement IFM, and the IFM array is partitioned using factor of <em>ifm_ch_proc</em> on the first dimension, and the partition way is <em>cyclic</em>. (Details pls refer to <a href="https://www.xilinx.com/html_docs/xilinx2018_2/sdaccel_doc/pragma-hls-array_partition-gle1504034361378.html" target="_blank" rel="external">HLS Pragma</a>).</p>
<p>The factor <em>ifm_ch_proc</em> means, the number of BRAM being accessed simultaneously is <em>ifm_ch_proc</em>. In other words, it requires “at least” <em>ifm_ch_proc</em> different BRAMs to store one IFM. Here, I use “at least” for the reason that <em>ifm_len</em> may be too large that one BRAM cannot hold the whole data.</p>
<p>With the knowledge of array partition, we can analyze the usage of BRAM for each kind of buffers. Before going deeper, we first introduce the metrics related to BRAM: (1) the words used in each BRAM and (2) The number of BRAMs. Now, we take IFM_BUF as an example to analyze the number of BRAM required for each kind of buffer.</p>
<p>#####IFM_BUF</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">static FPGA_DATA IFM[ifm_ch_mem][ifm_len];</div><div class="line">#pragma HLS RESOURCE variable=IFM core=RAM_1P_BRAM</div><div class="line">#pragma HLS ARRAY_PARTITION variable=IFM cyclic factor=ifm_ch_proc dim=1</div></pre></td></tr></table></figure>
<p>We can obtain the following information from the above codes.</p>
<ul>
<li>The size of IFM is $ifm\_ch\_mem\times ifm\_len$.</li>
<li>The partition factor is $ifm\_ch\_proc$.</li>
<li>For each partition, there are totally $\frac{ifm\_ch\_mem\times ifm\_len}{ifm\_ch\_proc}$ data needing to be stored. With the consideration of 16-bit fixed point, the number of BRAM required for each partition is $\left\lceil 18K/( \frac{ifm\_ch\_mem\times ifm\_len}{ifm\_ch\_proc}\times 16)\right\rceil$.</li>
</ul>
<p>In summary, the number of BRAM used by IFM is $\left\lceil 18K/( \frac{ifm\_ch\_mem\times ifm\_len}{ifm\_ch\_proc}\times 16)\right\rceil \times ifm\_ch\_proc$.</p>
<p>#####weight_BUF and OFM_BUF</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line">  static FPGA_WEIGHTS WEIGHT[ofm_ch_mem][ifm_ch_mem][kernel_size];</div><div class="line">#pragma HLS RESOURCE variable=WEIGHT core=RAM_1P_BRAM</div><div class="line">#pragma HLS ARRAY_PARTITION variable=WEIGHT cyclic factor=ofm_ch_proc/2 dim=1</div><div class="line">#pragma HLS ARRAY_PARTITION variable=WEIGHT cyclic factor=ifm_ch_proc/2 dim=2</div><div class="line">#pragma HLS ARRAY_PARTITION variable=WEIGHT complete dim=3</div><div class="line"></div><div class="line">	static FPGA_DATA OFM[ofm_ch_mem][ofm_len];</div><div class="line">#pragma HLS RESOURCE variable=OFM core=RAM_S2P_BRAM</div><div class="line">#pragma HLS ARRAY_PARTITION variable=OFM cyclic factor=ofm_ch_proc dim=1</div></pre></td></tr></table></figure>
<table>
<thead>
<tr>
<th>Buffers</th>
<th># of Partition</th>
<th># of BRAM</th>
</tr>
</thead>
<tbody>
<tr>
<td>IFM</td>
<td>$P=ifm\_ch\_proc$</td>
<td>$\left\lceil ( \frac{ifm\_ch\_mem\times ifm\_len}{P}\times 16)/18K\right\rceil \times P$</td>
</tr>
<tr>
<td>OFM</td>
<td>$P=ofm\_ch\_proc$</td>
<td>$\left\lceil ( \frac{ofm\_ch\_mem\times ofm\_len}{P}\times 16)/18K\right\rceil \times P$</td>
</tr>
<tr>
<td>WEIGHTs</td>
<td>$P=\frac{ofm\_ch\_proc\times ifm\_ch\_proc \times kernel\_size}{4}$</td>
<td>$\left\lceil ( \frac{ofm\_ch\_mem\times ifm\_ch\_mem\times kernel\_size}{P}\times 16)/18K\right\rceil \times P$</td>
</tr>
</tbody>
</table>
<p>####Simplify and Example</p>
<p>To simplify the above formulas, we create a mapping table to use simpler notations. The mapping table is given as follows. In the meanwhile, we use convolution 3 as an example. The corresponding value of each variable is also given in this table.</p>
<table>
<thead>
<tr>
<th>Original Notation</th>
<th>New Notation</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>ifm_ch_mem</td>
<td>$I_m$</td>
<td>64</td>
</tr>
<tr>
<td>ifm_ch_proc</td>
<td>$I_p$</td>
<td>8</td>
</tr>
<tr>
<td>ifm_len</td>
<td>$I_{len}$</td>
<td>13*13</td>
</tr>
<tr>
<td>ofm_ch_mem</td>
<td>$O_m$</td>
<td>64</td>
</tr>
<tr>
<td>ofm_ch_proc</td>
<td>$O_p$</td>
<td>8</td>
</tr>
<tr>
<td>ofm_len</td>
<td>$O_{len}$</td>
<td>13*13</td>
</tr>
<tr>
<td>kernel_size</td>
<td>$K$</td>
<td>9</td>
</tr>
</tbody>
</table>
<p>Using these simplified notations, let’s rewrite these formulas.</p>
<table>
<thead>
<tr>
<th>Buffers</th>
<th># of Partition</th>
<th># of BRAM</th>
</tr>
</thead>
<tbody>
<tr>
<td>IFM</td>
<td>$I_p=8$</td>
<td>$\left\lceil(\frac{I<em>m\times I</em>{len}}{1125\times I_p})\right\rceil\times I_p=\left\lceil 1.20\right\rceil\times 8=16$</td>
</tr>
<tr>
<td>OFM</td>
<td>$O_{p}=8$</td>
<td>$\left\lceil (\frac{O<em>{m}\times O</em>{len}}{1125\times O<em>{p}})\right\rceil \times O</em>{p}=\left\lceil 1.20 \right\rceil \times 8=16$</td>
</tr>
<tr>
<td>WEIGHTs</td>
<td>$\frac{O_{p}\times I_p \times K}{4}=144$</td>
<td>$\left\lceil ( \frac{4\times O_{m}\times I<em>m\times K}{1125\times O</em>{p}\times I<em>p \times K})\right\rceil \times \frac{O</em>{p}\times I_p \times K}{4}=\left\lceil 0.2275 \right\rceil \times 144=144$</td>
</tr>
</tbody>
</table>
<p>Based on the above table, we know that the number of BRAM used in the design for IFM, OFM, and WEIGHTs is 16+16+144=176, which exactly the same with that obtained from HLS and post-implementation.</p>
<p>####Efficiency of using BRAMs</p>
<p>In the above sections, we understand how many BRAM will be involved in terms of array partition. Now, let’s go further to see the efficiency of using BRAMs. Considering that the 18K BRAM, the efficiency means the percentage of space in 18K used for storing data. For example, if 9K IN 18k IS used, then the efficiency is 50%.</p>
<p>We build the following formulas to compute the BRAM efficiency for different types of buffers.</p>
<table>
<thead>
<tr>
<th>Buffers</th>
<th>Efficiency of BRAM</th>
<th>Example</th>
</tr>
</thead>
<tbody>
<tr>
<td>IFM</td>
<td>$(\frac{I<em>m\times I</em>{len}}{I_p}\times 16) /(\left\lceil \frac{I<em>m\times I</em>{len}}{1125\times I_p}\right\rceil\times 18K)$</td>
<td>$\frac{64\times 13\times 13\times 16}{8} / 36K = 60.08\%$</td>
</tr>
<tr>
<td>OFM</td>
<td>$(\frac{O<em>m\times O</em>{len}}{O_p}\times 16) /(\left\lceil \frac{O<em>m\times O</em>{len}}{1125\times O_p}\right\rceil\times 18K)$</td>
<td>$\frac{64\times 13\times 13\times 16}{8} / 36K = 60.08\%$</td>
</tr>
<tr>
<td>WEIGHTs</td>
<td>$(\frac{4\times O_{m}\times I<em>m\times K}{O</em>{p}\times I<em>p \times K}\times 16) /\left\lceil ( \frac{4\times O</em>{m}\times I<em>m\times K}{1125\times O</em>{p}\times I_p \times K})\right\rceil\times 18K$</td>
<td>$4096/18K=22.75\%$</td>
</tr>
</tbody>
</table>
<p><br></p>
<p><div align="right"><br><b>Weiwen Jiang</b><br><br><br>Jul 19, 2018<br><br><br><a href="mailto:jiang.wwen@pitt.edu" target="_blank" rel="external">jiang.wwen@pitt.edu</a><br><br><br>At UPITT<br></div><br><br></p>

          
        </div>
        <footer class="article-footer">
          <a data-url="https://wjiang.nd.edu/2018/07/19/blog_2018-07-19-Analysis/" data-id="ckdgp2kk8000dc4uodu88qqlz" class="article-share-link">Share</a>
          
          
        </footer>
      </div>
      <!-- 
        
<nav id="article-nav">
  
    <a href="/2018/08/01/blog_2018-08-01-DoubleBufferDesign/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Récent</strong>
      <div class="article-nav-title">
        
          Design NN on ZCU102 (3) — Double Buffer Design
        
      </div>
    </a>
  
  
    <a href="/2018/07/14/blog_18-07-14-Window/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Ancien</strong>
      <div class="article-nav-title">Design NN on ZCU102 (2) — Slide Window in HLS</div>
    </a>
  
</nav>

       -->
    </article>

           



</div>        
      
      <div style="clear:both;">
        <div>
        <br /><a href='https://clustrmaps.com/site/1a9dt'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=a1b7dd&w=200&t=tt&d=y7uhNSQnn7BwOiSgdjrJlsl50phjgSmRvL7A-puzXmA&co=f1f1f1&ct=a1b7dd' style="margin-top:20px;" /></a><br /></div>
      </div>

      </div> 

      <!--<footer id="footer" style="background: #A9A9A9; color: black; min-width:1200px;">
  
  <div class="outer" style="color:#000">
    <div id="footer-info" class="inner">	  	  	  
	  <div style="float:left">
	  Total pageviews: <a href="http://www.amazingcounters.com"><img border="0" src="http://cc.amazingcounters.com/counter.php?i=3223307&c=9670234" alt="AmazingCounters.com"></a><br />
      Last modified: Feb. 2019. <br />
      &copy; 2020 Weiwen Jiang<br>	  
	  </div>
	  <div style="float:right"><a href="https://clustrmaps.com/site/1a9dt" title="Visit tracker"><img src="//clustrmaps.com/map_v2.png?cl=a1b7dd&w=a&t=tt&d=y7uhNSQnn7BwOiSgdjrJlsl50phjgSmRvL7A-puzXmA&co=f1f1f1&ct=a1b7dd" /></a><br /></div>
    </div>	
  </div>
</footer>-->


  


<div class="wrapper container-fluid" style="clear:both; min-width:1200px">
      <div class="row">
      <footer id="footer" class="site-footer col-12" role="contentinfo" style="margin-bottom: 2em; padding-left: 2em; padding-right: 2em; padding-bottom: 2em;">
          <div class="footer-inner">
            <div class="vcard">
              <p class="copyright fn org">
                <a href="https://www.nd.edu/copyright/">Copyright</a> &copy; 2019
                <a href="https://www.nd.edu/" class="org">University of Notre Dame</a>
              </p>
              <p class="contact-info url adr">
                <a href="/" class="site-link url fn">Weiwen Jiang's Personal Website</a>
                <span class="address"><span class="street-address">254 Fitzpatrick Hall of Engineering</span>, <span class="locality">Notre Dame</span>, <span class="region" title="Indiana">IN</span> <span class="postal-code">46556</span></span>
                <span class="tel phone"><span class="type">Phone</span> (412)427-0695</span>
                <span class="email"><a href="mailto:wjiang2@nd.edu">wjiang2@nd.edu</a></span>
              </p>
              <a href="https://www.nd.edu/" class="ndmark"><img src="https://static.nd.edu/images/marks/blue/ndmark300.png" alt="University of Notre Dame"></a>
            </div>
          </div>
        </footer>
      </div>
    </div>



    </div> 
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link" style="color:white">Home</a>
  
    <a href="/categories/paper" class="mobile-nav-link" style="color:white">Publication</a>
  
    <a href="/categories/research" class="mobile-nav-link" style="color:white">Research</a>
  
    <a href="/categories/teaching" class="mobile-nav-link" style="color:white">Teaching</a>
  
    <a href="/categories/service" class="mobile-nav-link" style="color:white">Service</a>
  
    <a href="/categories/awards" class="mobile-nav-link" style="color:white">Awards</a>
  
    <a href="/categories/bio" class="mobile-nav-link" style="color:white">Bio</a>
  
    <a href="/categories/QF" class="mobile-nav-link" style="color:white">QuantumFlow</a>
  
</nav>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css">
  <script src="/fancybox/jquery.fancybox.pack.js"></script>


<script src="/js/script.js"></script>


    
   

  </div>  

  
</body>
</html>